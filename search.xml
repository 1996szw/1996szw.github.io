<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【毕设】Hadoop完全分布式平台搭建]]></title>
    <url>%2F2018%2F01%2F07%2F%E3%80%90%E6%AF%95%E8%AE%BE%E3%80%91Hadoop%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Info: 毕业设计课题基础Hadoop环境搭建 步入大四，毕设也是今年的重中之重，学校给我分配的课题是《基于大数据平台的关联规则算法的研究与实现》。之前没有接触过大数据的我也是要从头开始相关的学习，比如Hadoop环境的配置、关联规则算法的python实现、还有如何将Apriori算法在MapReduce上面并行化等等等等。本文就是Hadoop完全分布式平台的搭建记录。 另外也要感谢我校嵌入式研究中心的主任李超老师，给我提供了性能可靠的物理服务器来进行该课题的研究。 搭建Hadoop全分布式集群前提虚拟机软件的安装网上随便找的Vmware workstation，然后在centOS官网找个镜像装一下就OK了。但由于自己是学校给的服务器，所以略过这一步。 虚拟机的网络如果是在一台虚拟机中安装多个Linux操作系统的话，可以使用NAT或桥接模式都是可以的。 步骤： 在要使用的虚拟机的标签上右键单击，选择设置，选择网络适配器，选择桥接模式，确定。 设置完成之后，重启一下虚拟机。 再设置桥接之前将固定的IP取消： 桌面版：通过图形化界面设置的。 服务器版：在/etc/network/interfacesiface ens33 inet dhcp #address ... ifconfig获取IP。 最后试一试能不能ping通。 文件读写权限在linux下，软件安装到/opt下，当前正在使用的用户，对于opt目录需要有读写权限： 1）将opt的权限给为777（漏洞文件），不推荐在生产环境中使用。但是可以在学习和调试环境中使用。 2）sudo 在启动Hadoop的各个守护进程的时候，需要使用sudo。 在管理Hadoop的时候，实际上由不同的用户启动不同集群的守护进程。 统一使用当前的用户管理所有集群。 3）该目录的所有者设置为当前用户 安装JDK，配置Java环境1）将jdk安装包放在家目录下 2）解压到opt目录下 sudo tar zxvf jdk-8u131-linux-x64.tar.gz -C /opt 此时在/opt目录下：会有一个jdk1.8.0_131 3）创建软链接 sudo ln -snf /opt/jdk1.8.0_131 /opt/jdk 注意：创建软连接的目的是为了，我们在做项目的时候，可能会用到不同的jdk版本，这是要换软件的话，只需要修改软链接就可以了。而不用修改配置文件。 4）配置环境变量 局部环境变量：~/.bashrc 全局环境变量：/etc/profile export JAVA_HOME=/opt/jdk export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=.:$JAVA_HOME/lib export PATH=$PATH:$JAVA_HOME/bin source 相关文件（更新配置文件） 5）查看是否安装成功 java、javac、java -version 搭建伪分布式集群安装Hadoop1）解压hadoop安装包到opt目录下 sudo tar zxvf hadoop-2.8.1.tar.gz -C /opt 2）创建软链接 ln -snf /opt/hadoop-2.8.1 /opt/hadoop 3）配置环境变量 在/etc/profile文件中加入以下内容： export HADOOP_HOME=/opt/hadoop export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin source /etc/profile 4）使用hadoop version命令测试是否配置成功 配置Hadoop配置文件存放在/opt/hadoop/etc/hadoop中有很多个文件，暂时只需要修改的只有几个 1）hadoop-env.sh export JAVA_HOME=${JAVA_HOME}改成export JAVA_HOME=/opt/jdk 注意：在配置文件中有提示我们怎么设置，我们一般不删除，二回选择注释它的提示。 2）core-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://1.0.0.5:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 分析：1.0.0.5是你主节点所在主机的ip，而9000为端口 3）hdfs-site.xml 1234567891011121314151617181920212223&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hadoop-cluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///data/hadoop/hdfs/nn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.ch eckpoint.dir&lt;/name&gt; &lt;value&gt;file:///data/hadoop/hdfs/snn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.edits.dir&lt;/name&gt; &lt;value&gt;file:///data/hadoop/hdfs/snn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///data/hadoop/hdfs/dn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 4）mapred-site.xml 在hadoop的相关目录中没有此文件，但是有一个mapred-site.xml.template文件，将该文件复制一份为mapred-site.xml cp mapred-site.xml.template mapred-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5）yarn-site.xml 12345678910111213141516&lt;configuration&gt; &lt;!-- 指定ResourceManager的地址--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;1.0.0.5&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定reducer获取数据的方式--&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt; &lt;value&gt;file:///data/hadoop/yarn/nm&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; Hadoop目录权限问题注意： 如果使用sudo启动hadoop的相关进程，这几个目录的权限可以不用管。如果是使用当前的用户启动相关进程，对于opt目录，当前用户得有读写权限，对于/data目录也需要读写权限。 sudo mkdir -p /data/hadoop/hdfs/nn sudo mkdir -p /data/hadoop/hdfs/dn sudo mkdir -p /data/hadoop/hdfs/snn sudo mkdir -p /data/hadoop/yarn/nm 启动Hadoop启动HDFS集群 hadoop-daemon.sh start namenode 启动主节点 hadoop-daemon.sh start datanode 启动从节点 启动YARN集群yarn-daemon.sh start resourcemanager yarn-daemon.sh start nodemanager 启动作业历史服务器mr-jobhistory-daemon.sh start historyserver jps命令查看是否启动成功 HDFS和YARN集群都有相对应的WEB监控页面HDFS：http://ip:50070 YARN：http://ip:8088 YARN集群的操作—-测试Hadoop是否配置成功计算PI值的作业： yarn jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar pi 4 100 配置免密码登录1）在所有的主从节点中执行 如果以前配置过免密登录的话，建议删除重新建立过，因为我们需要配置的是多台服务器： rm -r ~/.ssh 执行ssh-keygen为了在主节点中生成公钥和私钥，在从从节点生成.ssh目录 2）在主节点中执行 scp ~/.ssh/id_rsa.pub 从节点的用户名@从节点ip:~ 注意：第一次远程连接的话，首先输入yes，然后是从节点密码 3）在所有的从节点中执行 我们把主节点的公钥已经拿到了所有的从节点中，接下来就是： cat id_rsa.pub&gt;&gt;.ssh/authorized_keys当中]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>毕业设计</tag>
        <tag>graduation</tag>
        <tag>hadoop</tag>
        <tag>环境配置</tag>
      </tags>
  </entry>
</search>
